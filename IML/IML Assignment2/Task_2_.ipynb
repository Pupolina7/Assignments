{"cells":[{"cell_type":"markdown","id":"ad909418-3384-444f-a7b6-f85a80eefa27","metadata":{"id":"ad909418-3384-444f-a7b6-f85a80eefa27"},"source":["# Assignment 2\n","\n","This assignment serves as a comprehensive evaluation of your machine learning skills, encompassing not only the technical aspects of model development but also your ability to analyze, interpret, and present data insights effectively. As such, it's essential to ensure that your submission is complete, functional, and devoid of any obvious gaps, as if you were delivering this project to a client.\n","\n","To achieve this, leverage the full capabilities of Markdown and the interactive visualization tools available in Jupyter notebooks to craft a well-structured and visually appealing report of your findings. Your report should clearly communicate the insights you've gained from the exploratory data analysis, the rationale behind your data preprocessing and feature engineering decisions, and a thorough analysis of feature importance. High-quality visualizations and well-organized documentation will not only support your analysis but also make your results more accessible and understandable to your audience.\n","\n","Remember, the ability to present complex results in an intuitive and engaging manner is a crucial skill, almost as important as the technical proficiency in model building and data analysis. Treat this assignment as an opportunity to showcase your skills in both areas.\n","\n","## Instructions\n","- Your submission should be a `.ipynb` file with your name,\n","  like `FirstnameLastname.ipynb`. It should include the answers to the questions in markdown cells, your data analysis and results.\n","- You are expected to follow the best practices for code writing and model\n","training. Poor coding style will be penalized.\n","- You are allowed to discuss ideas with your peers, but no sharing of code.\n","Plagiarism in the code will result in failing. If you use code from the\n","internet, cite it by adding the source of the code as a comment in the first line of the code cell. [Academic misconduct policy](https://wiki.innopolis.university/display/DOE/Academic+misconduct+policy)\n","- In real life clients can give unclear goals or requirements. So, if the instructions seem vague, use common sense to make reasonable assumptions and decisions.\n","\n","## Self-Reliance and Exploration\n","In this task, you're encouraged to rely on your resourcefulness and creativity. Dive into available resources, experiment with various solutions, and learn from every outcome. While our team is here to clarify task details and offer conceptual guidance, we encourage you to first seek answers independently. This approach is vital for developing your problem-solving skills in machine learning.\n","\n"]},{"cell_type":"markdown","id":"f38d3afb-58f8-4335-8fac-074db8adeaa7","metadata":{"id":"f38d3afb-58f8-4335-8fac-074db8adeaa7"},"source":["# Task 2: Image Classification with CNNs (50%)\n","\n","In this task, you'll dive into the world of Convolutional Neural Networks (CNNs) by working with the CIFAR-10 dataset, a staple in image classification challenges. Your goal is to build and evaluate two different CNN models to classify images into one of the ten categories accurately.\n","\n","The dataset is availabel in pytorch and keras.\n","\n","## Part 1: Custom CNN Model (20%)\n","\n","- Design and train a CNN model from scratch tailored for the CIFAR-10 dataset.\n","- Focus on the architecture that you believe will perform best for this specific task.\n","- Integrate various techniques such as batch normalization, dropout, learning rate schedulers, and early stopping to improve model training. Experiment with these methods and finetune them to see how they affect training stability, convergence speed, and overall performance.\n","\n","## Part 2: Transfer Learning Model (20%)\n","\n","- Implement a transfer learning approach using a pre-trained model of your choice.\n","- Fine-tune the model on the CIFAR-10 dataset to achieve the best possible performance.\n","\n","## Evaluation (10%)\n","\n","Ensure that both models are robust and generalized well to unseen data.\n","\n","After training both models, you will evaluate them on a provided test dataset.\n","\n","Compare your models based on:\n","- **AUC-ROC**: How well does each model discriminate between classes?\n","- **Model Size**: Consider the trade-offs in model complexity.\n","- **Inference Speed**: Evaluate how quickly your model can predict classes for new images.\n","\n","Reflect on the performance, size, and inference speed of both models. What insights can you draw from these comparisons?\n","\n","### Learning Objectives\n","\n","- Understand and apply CNNs for image classification.\n","- Explore the impact of model architecture on performance and efficiency.\n","- Learn the process and benefits of transfer learning in deep learning.\n","\n","Remember, the key to this task is not just about achieving the highest accuracy but also understanding the strengths and limitations of different approaches in machine learning model development."]},{"cell_type":"markdown","id":"atFaUsR9UmSq","metadata":{"id":"atFaUsR9UmSq"},"source":["**Part 1: Custom CNN Model**"]},{"cell_type":"code","execution_count":2,"id":"e94cdbd8-79b5-43ac-b0e1-0858da622e6e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e94cdbd8-79b5-43ac-b0e1-0858da622e6e","outputId":"ef16fef9-e4ee-4ec0-8410-4a57e26160f5","executionInfo":{"status":"ok","timestamp":1714220069058,"user_tz":-180,"elapsed":1742,"user":{"displayName":"Полина Пушкарева","userId":"02081912804445371474"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["import torch\n","from torch.utils import data\n","from torchvision import datasets, transforms\n","\n","train_batch_size = 128\n","test_batch_size = 128\n","\n","# put augmentations\n","train_transforms = transforms.Compose([\n","    transforms.RandomCrop(32, padding=2),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomRotation(10),\n","    transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","test_transforms = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","train_dataset = datasets.CIFAR10(root='cifar10',\n","                                 train=True,\n","                                 transform=train_transforms,\n","                                 download=True)\n","\n","train_data_loader = data.DataLoader(train_dataset,\n","                                    batch_size=train_batch_size,\n","                                    shuffle=True,\n","                                    drop_last=True,\n","                                    num_workers=2)\n","\n","test_dataset = datasets.CIFAR10(root='cifar10',\n","                                 train=False,\n","                                 transform=test_transforms,\n","                                 download=True)\n","\n","test_data_loader = data.DataLoader(test_dataset,\n","                                    batch_size=test_batch_size,\n","                                    shuffle=False,\n","                                    num_workers=2)"]},{"cell_type":"code","execution_count":3,"id":"8AIipBsgXjRd","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":302},"id":"8AIipBsgXjRd","outputId":"fa60f57d-31f2-48f6-c338-92f8d7ce46ce","executionInfo":{"status":"ok","timestamp":1714220069828,"user_tz":-180,"elapsed":774,"user":{"displayName":"Полина Пушкарева","userId":"02081912804445371474"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 4 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["# check the results of transformations\n","import matplotlib.pyplot as plt\n","images, _ = next(iter(train_data_loader))\n","\n","fig, axs = plt.subplots(nrows=1, ncols=4)\n","\n","for i in range(4):\n","    ax = axs[i]\n","    ax.imshow(images[i].numpy().transpose(1,2,0))\n","    ax.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":4,"id":"-qTjpiQFX0-0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-qTjpiQFX0-0","outputId":"bd82dc78-842a-4cdd-e252-ce5c4dbff0cd","executionInfo":{"status":"ok","timestamp":1714220070284,"user_tz":-180,"elapsed":466,"user":{"displayName":"Полина Пушкарева","userId":"02081912804445371474"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cuda\n","CustomModel(\n","  (conv1): Sequential(\n","    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU()\n","    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (conv2): Sequential(\n","    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU()\n","    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (3): Dropout(p=0.25, inplace=False)\n","  )\n","  (conv3): Sequential(\n","    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU()\n","    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (linear1): Sequential(\n","    (0): Linear(in_features=32768, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Dropout(p=0.1, inplace=False)\n","    (3): Linear(in_features=512, out_features=10, bias=True)\n","  )\n",")\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# define custom model\n","class CustomModel(nn.Module):\n","    def __init__(self):\n","        super(CustomModel, self).__init__()\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels=3,\n","                out_channels=32,\n","                padding=1,\n","                kernel_size=3),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2),\n","            nn.BatchNorm2d(32)\n","        )\n","        self.conv2 = nn.Sequential(\n","            nn.Conv2d(in_channels=32,\n","                      out_channels=64,\n","                      kernel_size=3,\n","                      padding=1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(64),\n","            nn.Dropout(0.25)\n","        )\n","        self.conv3 = nn.Sequential(\n","            nn.Conv2d(in_channels=64,\n","                      out_channels=128,\n","                      kernel_size=3,\n","                      padding=1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(128),\n","        )\n","        self.linear1 = nn.Sequential(\n","            nn.Linear(128*16*16, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(512, 10)\n","        )\n","\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        x = self.conv3(x)\n","        x = torch.flatten(x, 1)\n","        x = self.linear1(x)\n","        return F.log_softmax(x, dim=1)\n","\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","model = CustomModel().to(device)\n","\n","print(f'Device: {device}')\n","\n","print(model)"]},{"cell_type":"code","execution_count":5,"id":"cqEDDBkya48f","metadata":{"id":"cqEDDBkya48f","executionInfo":{"status":"ok","timestamp":1714220070285,"user_tz":-180,"elapsed":9,"user":{"displayName":"Полина Пушкарева","userId":"02081912804445371474"}}},"outputs":[],"source":["import operator\n","import numpy as np\n","\n","class EarlyStopping():\n","    def __init__(self, tolerance=5, min_delta=0, mode='min'):\n","        '''\n","        :param tolerance: number of epochs that the metric doesn't improve\n","        :param min_delta: minimum improvement (was 0)\n","        :param mode: 'min' or 'max' to minimize or maximize the metric\n","        '''\n","        self.tolerance = tolerance\n","        self.min_delta = min_delta\n","        self.mode = mode\n","        self.counter = 0\n","        self.early_stop = False\n","        self.prev_metric = np.inf if mode == 'min' else -np.inf\n","        self.operation = operator.gt if mode == 'min' else operator.lt\n","\n","\n","    def __call__(self, metric)->bool:\n","        ''' This function should return True if `metric` is not improving for\n","            'tolerance' calls\n","        '''\n","        delta = (metric - self.prev_metric)\n","\n","        if self.operation(delta, self.min_delta):\n","            self.counter +=1\n","        else:\n","            self.counter = 0\n","            self.prev_metric = metric\n","\n","        if self.counter >= self.tolerance:\n","            self.early_stop = True\n","        return self.early_stop"]},{"cell_type":"code","execution_count":6,"id":"s_CKe0ubawkz","metadata":{"id":"s_CKe0ubawkz","executionInfo":{"status":"ok","timestamp":1714220070285,"user_tz":-180,"elapsed":8,"user":{"displayName":"Полина Пушкарева","userId":"02081912804445371474"}}},"outputs":[],"source":["from time import time\n","from tqdm import tqdm\n","\n","# define train function\n","def train(model, device, train_loader, criterion, optimizer, epoch):\n","    model.train()\n","    epoch_loss = 0\n","    start_time = time()\n","    correct = 0\n","    iteration = 0\n","\n","    bar = tqdm(train_loader)\n","    for data, target in bar:\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","\n","        output = model(data)\n","        pred = output.argmax(dim=1, keepdim=True)\n","        correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","        iteration += 1\n","        bar.set_postfix({\"Loss\": format(epoch_loss/iteration, '.6f')})\n","\n","    acc = 100. * correct / len(train_loader.dataset)\n","    print(f'\\rTrain Epoch: {epoch}, elapsed time:{time()-start_time:.2f}s')\n","    return epoch_loss, acc\n","\n","# define function to perform of test data\n","def test(model, device, test_loader, criterion):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += criterion(output, target).item()\n","            pred = output.argmax(dim=1, keepdim=True)\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    acc = 100. * correct / len(test_loader.dataset)\n","    return test_loss, acc"]},{"cell_type":"code","execution_count":10,"id":"jxwUZYGtZNnQ","metadata":{"id":"jxwUZYGtZNnQ","executionInfo":{"status":"ok","timestamp":1714220433469,"user_tz":-180,"elapsed":303,"user":{"displayName":"Полина Пушкарева","userId":"02081912804445371474"}}},"outputs":[],"source":["from torch.optim import SGD, lr_scheduler\n","from copy import deepcopy\n","\n","# set up training parameters\n","epochs = 10 #40 Train-76.26% test-80.18%\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = SGD(model.parameters(), lr=0.1, momentum=0.9)\n","scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min',\n","                                           factor=0.3, patience=3,\n","                                           verbose=True, min_lr=0.001)\n","early_stopping = EarlyStopping(tolerance=7, mode='min')\n","\n","best_model_wts = deepcopy(model.state_dict())"]},{"cell_type":"code","execution_count":13,"id":"wipoS43WZ6T7","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":824},"id":"wipoS43WZ6T7","outputId":"e860f1c0-ab08-4048-c33d-7378b7cfdf4e","executionInfo":{"status":"error","timestamp":1714221026693,"user_tz":-180,"elapsed":35998,"user":{"displayName":"Полина Пушкарева","userId":"02081912804445371474"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 390/390 [00:33<00:00, 11.77it/s, Loss=2.304202]\n"]},{"output_type":"stream","name":"stdout","text":["\rTrain Epoch: 1, elapsed time:33.13s\n","\n","Early stopping\n","\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"File CustomModel(\n  (conv1): Sequential(\n    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (conv2): Sequential(\n    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): Dropout(p=0.25, inplace=False)\n  )\n  (conv3): Sequential(\n    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (linear1): Sequential(\n    (0): Linear(in_features=32768, out_features=512, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.1, inplace=False)\n    (3): Linear(in_features=512, out_features=10, bias=True)\n  )\n).pt cannot be opened.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-bb104e868ce8>\u001b[0m in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-13-bb104e868ce8>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(train_model, writing)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training loss {train_loss}, test loss {test_loss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{train_model}.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model_wts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"best_{train_model}.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_disable_byteorder_record\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0mcontainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_zipfile_writer_buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: File CustomModel(\n  (conv1): Sequential(\n    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (conv2): Sequential(\n    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): Dropout(p=0.25, inplace=False)\n  )\n  (conv3): Sequential(\n    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (linear1): Sequential(\n    (0): Linear(in_features=32768, out_features=512, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.1, inplace=False)\n    (3): Linear(in_features=512, out_features=10, bias=True)\n  )\n).pt cannot be opened."]}],"source":["import torch.optim as optim\n","from torch.utils.tensorboard import SummaryWriter\n","import copy\n","epochs=2\n","def training(train_model\n","             , writing=False\n","             ):\n","    if writing:\n","        writer = SummaryWriter(log_dir=f'runs/{train_model}')\n","    best_acc = 0.0\n","    for epoch in range(1, epochs + 1):\n","        train_loss, train_acc = train(train_model, device, train_data_loader, criterion, optimizer, epoch)\n","        # Update learning rate if needed\n","        scheduler.step(train_loss)\n","\n","        test_loss, test_acc = test(train_model, device, test_data_loader, criterion)\n","        # Terminate training if loss stopped to decrease\n","        if early_stopping(test_loss):\n","            print('\\nEarly stopping\\n')\n","            break\n","        # Deep copy the weight of model if its accuracy is the best for now\n","        if test_acc > best_acc:\n","            best_acc = test_acc\n","            best_model_wts = copy.deepcopy(train_model.state_dict())\n","        if writing:\n","            writer.add_scalars('Loss',\n","                            {\n","                                'train': train_loss,\n","                                'test': test_loss\n","                            },\n","                            epoch)\n","\n","            writer.add_scalars('Accuracy',\n","                            {\n","                                'train': train_acc,\n","                                'test': test_acc\n","                            },\n","                            epoch)\n","        else:\n","            print(f\"Training accuracy {train_acc}, test accuracy {test_acc}\")\n","            print(f\"Training loss {train_loss}, test loss {test_loss}\")\n","\n","    torch.save(train_model.state_dict(), f\"{train_model}.pt\")\n","    train_model.load_state_dict(best_model_wts)\n","    torch.save(train_model.state_dict(), f\"best_{train_model}.pt\")\n","    if writing:\n","        writer.close()\n","\n","training(train_model=model)"]},{"cell_type":"code","execution_count":null,"id":"gissPUJpZy2g","metadata":{"id":"gissPUJpZy2g","executionInfo":{"status":"aborted","timestamp":1714220285245,"user_tz":-180,"elapsed":9,"user":{"displayName":"Полина Пушкарева","userId":"02081912804445371474"}}},"outputs":[],"source":["# evaluate the trained custom model on test dataset\n","model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in test_data_loader:\n","        images, labels = data[0].to(device), data[1].to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print(f\"Accuracy of a Custom Model on test set: {100 * correct / total}%\")"]},{"cell_type":"markdown","id":"iHUP-d1sUrMT","metadata":{"id":"iHUP-d1sUrMT"},"source":["**Part 2: Transfer Learning Model**"]},{"cell_type":"code","execution_count":null,"id":"Imv57MX1Uvi1","metadata":{"id":"Imv57MX1Uvi1","executionInfo":{"status":"aborted","timestamp":1714220285246,"user_tz":-180,"elapsed":10,"user":{"displayName":"Полина Пушкарева","userId":"02081912804445371474"}}},"outputs":[],"source":["import torchvision.models as models\n","\n","# load pre-trained ResNet model\n","resnet = models.resnet18(pretrained=True)\n","num_ftrs = resnet.fc.in_features\n","resnet.fc = nn.Linear(num_ftrs, 10)\n","\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","resnet = resnet.to(device)\n","\n","print(f'\\nDevice: {device}')\n","\n","print(resnet)"]},{"cell_type":"code","execution_count":null,"id":"g-a4I6feyrNH","metadata":{"id":"g-a4I6feyrNH","executionInfo":{"status":"aborted","timestamp":1714220285246,"user_tz":-180,"elapsed":10,"user":{"displayName":"Полина Пушкарева","userId":"02081912804445371474"}}},"outputs":[],"source":["# set up training parameters\n","epochs = 40\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = SGD(resnet.parameters(), lr=0.1, momentum=0.9)\n","scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min',\n","                                           factor=0.3, patience=3,\n","                                           verbose=True, min_lr=0.001)\n","early_stopping = EarlyStopping(tolerance=7, mode='min')\n","\n","# best_model_wts = deepcopy(resnet.state_dict()) #check best_model_wts = deepcopy(model.state_dict())\n","\n","# train the pretrained model on the dataset\n","training(train_model=resnet)"]},{"cell_type":"code","execution_count":null,"id":"M0R9ObSZz5od","metadata":{"id":"M0R9ObSZz5od","executionInfo":{"status":"aborted","timestamp":1714220285247,"user_tz":-180,"elapsed":11,"user":{"displayName":"Полина Пушкарева","userId":"02081912804445371474"}}},"outputs":[],"source":["# evaluate the pretrained model on test dataset\n","resnet.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in test_data_loader:\n","        images, labels = data[0].to(device), data[1].to(device)\n","        outputs = resnet(images)\n","        _, predicted = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print(f\"Accuracy of a pretrained model (resnet) on test set: {100 * correct / total}%\")"]},{"cell_type":"markdown","id":"0em6j7dgUwBB","metadata":{"id":"0em6j7dgUwBB"},"source":["**Evaluation**"]},{"cell_type":"code","execution_count":null,"id":"DsSnKDoXUzsn","metadata":{"id":"DsSnKDoXUzsn","executionInfo":{"status":"aborted","timestamp":1714220285247,"user_tz":-180,"elapsed":10,"user":{"displayName":"Полина Пушкарева","userId":"02081912804445371474"}}},"outputs":[],"source":["import time\n","import numpy as np\n","from sklearn.metrics import roc_auc_score, accuracy_score\n","\n","# define function for accuracy calculation\n","def calculate_accuracy(model, testloader):\n","    model.eval()\n","    y_true = []\n","    y_pred = []\n","    with torch.no_grad():\n","        for images, labels in testloader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs, 1)\n","            y_true.extend(labels.cpu().numpy())\n","            y_pred.extend(predicted.cpu().numpy())\n","    accuracy = accuracy_score(y_true, y_pred)\n","    return accuracy\n","\n","# define function for AUC-ROC calculation\n","def calculate_auc_roc(model, testloader):\n","    model.eval()\n","    y_true = []\n","    y_scores = []\n","    with torch.no_grad():\n","        for data in testloader:\n","            images, labels = data[0].to(device), data[1].to(device)\n","            outputs = model(images)\n","            probabilities = torch.softmax(outputs, dim=1)\n","            y_true.extend(labels.cpu().numpy())\n","            y_scores.extend(probabilities.cpu().numpy())\n","    y_true = np.array(y_true)\n","    y_scores = np.array(y_scores)\n","    auc_roc = roc_auc_score(y_true, y_scores, multi_class='ovr')  # Specify 'macro' or 'weighted'\n","    return auc_roc\n","\n","\n","# define function for model size calculation\n","def calculate_model_size(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","# define function for inference speed measure\n","def measure_inference_speed(model, testloader):\n","    model.eval()\n","    start_time = time.time()\n","    with torch.no_grad():\n","        for data in testloader:\n","            images = data[0].to(device)\n","            _ = model(images)\n","    end_time = time.time()\n","    inference_time = end_time - start_time\n","    return inference_time"]},{"cell_type":"code","execution_count":null,"id":"VZsbDKIN2plH","metadata":{"id":"VZsbDKIN2plH","executionInfo":{"status":"aborted","timestamp":1714220285247,"user_tz":-180,"elapsed":10,"user":{"displayName":"Полина Пушкарева","userId":"02081912804445371474"}}},"outputs":[],"source":["import torch\n","import numpy as np\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","\n","# define a custom dataset to load test images and labels\n","class CustomTestDataset(Dataset):\n","    def __init__(self, images_file, labels_file, transform=None):\n","        self.images = np.load(images_file)\n","        self.labels = np.load(labels_file)\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        image = self.images[idx]\n","        label = self.labels[idx]\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, label\n","\n","test_transforms = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","evaluation_dataset = CustomTestDataset(images_file='task_2_test_images.npy',\n","                                       labels_file='task_2_test_labels.npy',\n","                                       transform=test_transforms)\n","\n","evaluation_loader = DataLoader(evaluation_dataset,\n","                               batch_size=test_batch_size,\n","                               shuffle=False)"]},{"cell_type":"code","execution_count":null,"id":"-FBH3vrZ1a8J","metadata":{"id":"-FBH3vrZ1a8J","executionInfo":{"status":"aborted","timestamp":1714220285248,"user_tz":-180,"elapsed":11,"user":{"displayName":"Полина Пушкарева","userId":"02081912804445371474"}}},"outputs":[],"source":["# evaluate Custom CNN Model\n","custom_cnn_accuracy = calculate_accuracy(model, evaluation_loader)\n","custom_cnn_auc_roc = calculate_auc_roc(model, evaluation_loader)\n","custom_cnn_model_size = calculate_model_size(model)\n","custom_cnn_inference_speed = measure_inference_speed(model, evaluation_loader)\n","\n","print(\"Custom CNN Model Evaluation:\")\n","print(f\"Accuracy: {custom_cnn_accuracy}\")\n","print(f\"AUC-ROC: {custom_cnn_auc_roc}\")\n","print(f\"Model Size: {custom_cnn_model_size} parameters\")\n","print(f\"Inference Speed: {custom_cnn_inference_speed} seconds\")"]},{"cell_type":"code","execution_count":null,"id":"uWPZpVep1f2u","metadata":{"id":"uWPZpVep1f2u","executionInfo":{"status":"aborted","timestamp":1714220285248,"user_tz":-180,"elapsed":11,"user":{"displayName":"Полина Пушкарева","userId":"02081912804445371474"}}},"outputs":[],"source":["# evaluate Transfer Learning Model\n","transfer_learning_accuracy = calculate_accuracy(resnet, evaluation_loader)\n","transfer_learning_auc_roc = calculate_auc_roc(resnet, evaluation_loader)\n","transfer_learning_model_size = calculate_model_size(resnet)\n","transfer_learning_inference_speed = measure_inference_speed(resnet, evaluation_loader)\n","\n","print(\"\\nTransfer Learning Model (ResNet-18) Evaluation:\")\n","print(f\"Accuracy: {transfer_learning_accuracy}\")\n","print(f\"AUC-ROC: {transfer_learning_auc_roc}\")\n","print(f\"Model Size: {transfer_learning_model_size} parameters\")\n","print(f\"Inference Speed: {transfer_learning_inference_speed} seconds\")"]},{"cell_type":"markdown","source":["Discussion on evaluation"],"metadata":{"id":"58dhj-t4d_dq"},"id":"58dhj-t4d_dq"}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":5}